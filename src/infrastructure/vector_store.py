# infrastructure/vector_store.py
import os
import shutil
from typing import List

from langchain_chroma import Chroma
from langchain_ollama import OllamaEmbeddings

# â¬‡ï¸ å¼•å…¥æˆ‘ä»¬çš„æ ¸å¿ƒæ¨¡åž‹
from src.core.models.domain_models import LifeEvent


class KnowledgeBase:
    def __init__(self, persist_dir: str = "./data/chroma_db", reset_db: bool = False):
        # ... (è¿™éƒ¨åˆ†ä¿æŒä¸å˜) ...
        self.persist_dir = persist_dir
        self.embeddings = OllamaEmbeddings(model="nomic-embed-text:latest")
        if reset_db and os.path.exists(persist_dir):
            shutil.rmtree(persist_dir)
        self.vector_db = Chroma(
            collection_name="echo_board_memory",
            embedding_function=self.embeddings,
            persist_directory=self.persist_dir
        )

    def add_events(self, events: List[LifeEvent]):
        """
        [å˜æ›´]: çŽ°åœ¨æŽ¥æ”¶å¼ºç±»åž‹çš„ LifeEvent åˆ—è¡¨
        """
        if not events:
            return

        # è½¬æ¢: LifeEvent -> LangChain Document
        docs = [event.to_langchain_document() for event in events]

        # å­˜å…¥ Chroma (ä½¿ç”¨ LifeEvent çš„ UUID ä½œä¸ºæ•°æ®åº“ ID)
        ids = [event.id for event in events]
        self.vector_db.add_documents(documents=docs, ids=ids)

        print(f"ðŸ’¾ [KnowledgeBase] å·²å­˜å…¥ {len(events)} ä¸ª LifeEvent å¯¹è±¡ã€‚")

    def search(self, query: str, k: int = 5) -> List[LifeEvent]:
        """
        [å˜æ›´]: è¿”å›ž LifeEvent åˆ—è¡¨ï¼Œè€Œä¸æ˜¯ Document
        """
        raw_docs = self.vector_db.similarity_search(query, k=k)

        # è½¬æ¢: LangChain Document -> LifeEvent
        return [LifeEvent.from_langchain_document(doc) for doc in raw_docs]
